{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOZc+zMcsM3EJlpkuJX3sO1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jewelrana77/02_update_apnacollege/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "first_possible_word={}\n",
        "second_possible_word={}\n",
        "transition={}"
      ],
      "metadata": {
        "id": "Cn5X7A6XP4Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expandDict(dictionary,key,value):  #storing into dictionary current word as a 'value' and previous word as a 'key'\n",
        "    if key not in dictionary:\n",
        "        dictionary[key]=[]\n",
        "    dictionary[key].append(value)"
      ],
      "metadata": {
        "id": "nokn_OT-QRJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_next_probability(word_list):  #finding probability of each word\n",
        "    word_list_length=len(word_list)\n",
        "    probability_dict={}\n",
        "    for item in word_list:\n",
        "        probability_dict[item]=probability_dict.get(item,0)+1  #calculating frequncy of any word\n",
        "    for key,value in probability_dict.items():  #calculating probability and store into dictionary according to thire key and probability as a value\n",
        "        probability_dict[key]=(value+1)/(word_list_length+9484)\n",
        "    probability_dict=sort_prob(probability_dict)\n",
        "    return probability_dict"
      ],
      "metadata": {
        "id": "gvANdzB6QWdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_prob(dictionary):  #sorting of dictionary through values\n",
        "    keys_list=list(dictionary.keys())\n",
        "    values_list = list(dictionary.values())\n",
        "    for i in range(len(values_list)-1):\n",
        "        for j in range(len(values_list)-i-1):\n",
        "            if values_list[j]<values_list[j+1]:\n",
        "                temp=values_list[j]\n",
        "                values_list[j]=values_list[j+1]\n",
        "                values_list[j+1]=temp\n",
        "                temp=keys_list[j]\n",
        "                keys_list[j]=keys_list[j+1]\n",
        "                keys_list[j+1]=temp\n",
        "\n",
        "    sort_dict={}\n",
        "    for i in range(len(values_list)):\n",
        "        sort_dict[keys_list[i]]=values_list[i]\n",
        "    return sort_dict"
      ],
      "metadata": {
        "id": "6QyCelYIQdxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainModel():\n",
        "\n",
        "    for line in open(\"/content/winter_bd.txt\"):\n",
        "        tokens=line.rstrip().lower().split()\n",
        "        tokens_length=len(tokens)\n",
        "        for i in range(tokens_length):\n",
        "            token=tokens[i]\n",
        "            if i==0:   #if word is ffirst word of every sentence\n",
        "                first_possible_word[token]=first_possible_word.get(token,0)+1\n",
        "            else:\n",
        "                prev_token=tokens[i-1]\n",
        "                if i==1:  #if word is 2nd word of the senetnce\n",
        "                    expandDict(second_possible_word,prev_token,token)\n",
        "                if i==tokens_length-1:  #if word is last of sentence\n",
        "                    expandDict(transition,(prev_token,token),'END')\n",
        "                else:\n",
        "                    prev_prev_token=tokens[i-2]\n",
        "                    expandDict(transition,(prev_prev_token,prev_token),token)\n",
        "\n",
        "    first_possible_word_total=sum(first_possible_word.values())  #finding total frequency n first_possible word\n",
        "    for key,value in first_possible_word.items():  #calculating probability of first word in each sentence and store according to that word\n",
        "        first_possible_word[key]=(value+1)/(first_possible_word_total+9484)\n",
        "\n",
        "    for prev_word,next_word_list in second_possible_word.items():\n",
        "        second_possible_word[prev_word]=get_next_probability(next_word_list)\n",
        "\n",
        "    for word_pair,next_word_list in transition.items():\n",
        "        transition[word_pair]=get_next_probability(next_word_list)"
      ],
      "metadata": {
        "id": "Lh5Z1HEGQlYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def next_word(tpl):\n",
        "    #print(transitions)\n",
        "    if(type(tpl) == str):   #it is first word of string.. return from second word\n",
        "        d = second_possible_word.get(tpl)   #tpl match with key and return value, value is already dictionary\n",
        "        if (d is not None):\n",
        "            return list(d.keys())[:5]   #since d is already dictionary so return keys\n",
        "        else:\n",
        "            #prob = 1 / 9484\n",
        "            prob = 1 / 5105\n",
        "            smooth_dict={}\n",
        "\n",
        "            for key in second_possible_word.keys():\n",
        "                dd=second_possible_word.get(key)\n",
        "                for key1,value1 in dd.items():\n",
        "                    if value1<=prob:\n",
        "                        smooth_dict[key1]=value1\n",
        "\n",
        "            return list(smooth_dict.keys())[:5]\n",
        "\n",
        "    if(type(tpl) == tuple): #incoming words are combination of two words.. find next word now based on transitions\n",
        "        d = transition.get(tpl)\n",
        "        if(d == None):\n",
        "            return \"\"\n",
        "        return list(d.keys())[:5]\n",
        "    return \"\" #wrong input.. return nothing"
      ],
      "metadata": {
        "id": "JT32Rqe6Qwrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    trainModel()\n",
        "    print(\"Enter something:\")\n",
        "    sent = ''\n",
        "    last_suggestion = []\n",
        "    while True:\n",
        "        user_input = input()\n",
        "        sent += user_input\n",
        "        tkns = sent.split()\n",
        "\n",
        "        if len(tkns) < 2:\n",
        "            last_suggestion = next_word(tkns[0].lower())\n",
        "            print(\"Suggestions:\", last_suggestion)\n",
        "        else:\n",
        "            last_suggestion = next_word((tkns[-2], tkns[-1]))\n",
        "            print(\"Suggestions:\", last_suggestion)\n",
        "\n",
        "    while (c != b'\\r'):  # stop when user preses enter\n",
        "        if (c!=b'\\t'):     #if previous character was tab, then it write 1st suggestion no wait for inputing\n",
        "            c=msvcrt.getch()  #inputing charcter by character\n",
        "        else:\n",
        "            c=b' '\n",
        "        if c!=b'\\t':\n",
        "            print(str(c.decode('UTF-8')),end='',flush=True)\n",
        "        sent=sent+str(c.decode('UTF-8'))\n",
        "        if c==b' ':\n",
        "            tkns=sent.split()\n",
        "            if len(tkns)<2:  #if 2nd word want to write after 1st\n",
        "                last_suggestion=next_word(tkns[0].lower())\n",
        "                print(last_suggestion,end=' ',flush=True)\n",
        "            else:\n",
        "                last_suggestion=next_word((tkns[-2],tkns[-1]))  #beacaue its a try gram model so we need to last and last to last word\n",
        "                print(last_suggestion,end=' ',flush=True)\n",
        "        if c==b'\\t' and len(last_suggestion)>0 :\n",
        "            print(last_suggestion[0],end=\" \",flush=True)\n",
        "            sent=sent+\" \"+last_suggestion[0]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J750SbvSMq2S",
        "outputId": "768740f2-4e2e-4e2a-9f5b-9867ff55c26b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter something:\n",
            "winter is\n",
            "Suggestions: ['a', 'also', 'the']\n",
            "The winter \n",
            "Suggestions: \n",
            "The winter\n",
            "Suggestions: \n",
            "The winter season \n",
            "Suggestions: ['in', 'is', 'can']\n",
            "winter\n",
            "Suggestions: \n",
            "winter \n",
            "Suggestions: \n",
            "one of the \n",
            "Suggestions: ['most', 'country,', 'bengali', 'date', 'delicious']\n",
            "one of the\n",
            "Suggestions: ['most', 'country,', 'bengali', 'date', 'delicious']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TEyewF4aTNpe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}